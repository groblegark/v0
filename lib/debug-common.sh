#!/bin/bash
# SPDX-License-Identifier: MIT
# Copyright (c) 2026 Alfred Jean LLC
# debug-common.sh - Shared debug collection utilities for v0 self debug
# Source this to get common debug report generation functions

# Ensure v0-common.sh is sourced first
if [[ -z "${V0_INSTALL_DIR:-}" ]]; then
    echo "Error: debug-common.sh requires v0-common.sh to be sourced first" >&2
    exit 1
fi

# ============================================================================
# Report Generation Functions
# ============================================================================

# Generate YAML-style frontmatter for debug report
# Usage: generate_frontmatter <op_name> [type] [phase] [status]
generate_frontmatter() {
    local op_name="$1"
    local type="${2:-unknown}"
    local phase="${3:-unknown}"
    local status="${4:-unknown}"
    local machine
    machine=$(hostname 2>/dev/null || echo "unknown")

    cat <<EOF
---
v0-debug-report: true
operation: ${op_name}
type: ${type}
phase: ${phase}
status: ${status}
machine: ${machine}
generated_at: $(date -u '+%Y-%m-%dT%H:%M:%SZ')
---
EOF
}

# Generate report summary section
# Usage: generate_summary <op_name> [state_file]
generate_summary() {
    local op_name="$1"
    local state_file="${2:-}"

    echo "# Debug Report: ${op_name}"
    echo ""
    echo "## Summary"
    echo ""

    if [[ -f "${state_file}" ]]; then
        local status phase
        status=$(jq -r '.status // "unknown"' "${state_file}")
        phase=$(jq -r '.phase // "unknown"' "${state_file}")
        echo "Operation **${op_name}** is in phase \`${phase}\` with status \`${status}\`."
    else
        echo "Debug report for \`${op_name}\`."
    fi
}

# Generate operation state section
# Usage: generate_operation_state <state_file>
generate_operation_state() {
    local state_file="$1"

    echo "## Operation State"
    echo ""

    if [[ -f "${state_file}" ]]; then
        echo '```json'
        jq '.' "${state_file}" 2>/dev/null || cat "${state_file}"
        echo '```'
    else
        echo "*No state file found*"
    fi
}

# Include a log file safely (with truncation for large files)
# Filters out debug report frontmatter, ANSI escape sequences, and TUI noise from tmux captures
# Usage: include_log_file <log_file> [max_lines] [label]
include_log_file() {
    local log_file="$1"
    local max_lines="${2:-500}"
    local label="${3:-Log}"

    if [[ ! -f "${log_file}" ]]; then
        echo "*No ${label} found*"
        return
    fi

    local line_count
    line_count=$(wc -l < "${log_file}" | tr -d ' ')

    echo '```'
    if (( line_count > max_lines )); then
        echo "# [Truncated: showing last ${max_lines} of ${line_count} lines]"
        tail -n "${max_lines}" "${log_file}" | filter_ansi_sequences | filter_tui_noise | filter_debug_frontmatter
    else
        filter_ansi_sequences < "${log_file}" | filter_tui_noise | filter_debug_frontmatter
    fi
    echo '```'
}

# Filter out debug report YAML frontmatter from log content
# This prevents tmux captures containing debug output from being included in logs
filter_debug_frontmatter() {
    grep -v -E '^(---|v0-debug-report:|operation:|type:|phase:|status:|machine:|generated_at:)' 2>/dev/null || cat
}

# Filter out ANSI escape sequences from log content
# This removes terminal color codes and cursor controls from tmux captures
filter_ansi_sequences() {
    # Use perl for comprehensive ANSI/terminal escape sequence removal:
    # - CSI sequences: ESC[ followed by parameters and command
    # - OSC sequences: ESC] ... (terminated by BEL or ST)
    # - Other escape sequences
    perl -pe '
        s/\e\[[0-9;?]*[A-Za-z]//g;           # CSI sequences (colors, cursor, etc)
        s/\e\][^\a\e]*(?:\a|\e\\)//g;        # OSC sequences (title, etc)
        s/\e\[[\x20-\x3f]*[\x40-\x7e]//g;    # Other CSI
        s/\e[PX^_].*?\e\\//g;                # DCS, SOS, PM, APC sequences
        s/\e.//g;                            # Any remaining ESC+char
    ' 2>/dev/null || cat
}

# Filter TUI noise from Claude Code log output
# Deduplicates spinner lines, horizontal rules, mode indicators, etc.
# Also filters streaming fragments and collapses excessive blank lines.
filter_tui_noise() {
    awk '
    # Normalize line for comparison (strip spinner chars and timestamps)
    function normalize(line) {
        # Replace spinner characters with placeholder
        gsub(/[✽✻✶✳✢·⏺⏵⏸]/, "X", line)
        # Remove all timing/status info in parentheses
        gsub(/\(ctrl\+c to interrupt[^)]*\)/, "(status)", line)
        gsub(/\([0-9]+s[^)]*\)/, "(status)", line)
        gsub(/\(thinking\)/, "(status)", line)
        gsub(/\(thought for [^)]*\)/, "(status)", line)
        # Remove token counts
        gsub(/[↓↑] *[0-9.]+k? *tokens?/, "", line)
        # Normalize whitespace
        gsub(/[[:space:]]+/, " ", line)
        gsub(/^ +| +$/, "", line)
        return line
    }

    # Check if line is a horizontal rule (mostly ─ chars)
    function is_hrule(line) {
        temp = line
        gsub(/[^─]/, "", temp)
        return length(temp) > 20
    }

    # Check if line is a spinner/status line (with status info)
    function is_spinner_status_line(line) {
        return line ~ /^[[:space:]]*[✽✻✶✳✢·⏺][[:space:]]/ && \
               (line ~ /ctrl\+c/ || line ~ /thinking/ || line ~ /thought/ || line ~ /tokens/)
    }

    # Check if line is a standalone spinner or spinner with minimal content
    # These are streaming fragments that should be filtered
    function is_spinner_fragment(line) {
        # Strip whitespace
        gsub(/^[[:space:]]+|[[:space:]]+$/, "", line)
        # Line is just spinner chars and/or very short text fragments
        if (line ~ /^[✽✻✶✳✢·⏺⏵⏸]+$/) return 1
        # Spinner followed by 1-3 chars including arrows (streaming fragment)
        if (line ~ /^[✽✻✶✳✢·⏺][[:alnum:][:punct:]↓↑←→]{0,3}$/) return 1
        # Just a few chars that look like streaming fragments (include arrows)
        if (length(line) <= 3 && line !~ /^[0-9]+\.?$/ && line !~ /^[-*>]$/) return 1
        return 0
    }

    # Check if line is a streaming text fragment (partial word/text)
    function is_streaming_fragment(line) {
        # Strip whitespace
        gsub(/^[[:space:]]+|[[:space:]]+$/, "", line)
        # Very short lines that are likely streaming fragments
        if (length(line) <= 2) return 1
        # Lines that are just ellipsis or partial text with ellipsis
        if (line ~ /^[a-z]…$/ || line ~ /^…[a-z]?$/) return 1
        # Single letters or digits (streaming output)
        if (line ~ /^[a-zA-Z]$/) return 1
        return 0
    }

    # Check if line is a mode indicator
    function is_mode_indicator(line) {
        return line ~ /⏵⏵.*\(shift\+tab/ || \
               line ~ /⏸.*\(shift\+tab/ || \
               line ~ /^\s*\? for shortcuts/ || \
               line ~ /Use meta\+[a-z] to/
    }

    # Check if line is a prompt placeholder
    function is_prompt_placeholder(line) {
        return line ~ /^❯[[:space:]]*Try "/
    }

    # Check if line is part of Claude Code logo
    function is_logo_line(line) {
        return line ~ /▐▛███▜▌/ || line ~ /▝▜█████▛▘/ || line ~ /▘▘ ▝▝/
    }

    # Check if line is just "Processing..." or similar status
    function is_processing_line(line) {
        gsub(/^[[:space:]]+|[[:space:]]+$/, "", line)
        return line ~ /^Processing…?$/ || line ~ /^Running…?$/
    }

    {
        # Track blank lines to collapse multiples
        if ($0 ~ /^[[:space:]]*$/) {
            blank_count++
            # Only emit first blank line in a sequence
            if (blank_count == 1) print
            next
        }
        blank_count = 0

        norm = normalize($0)

        # Skip spinner fragments and streaming fragments
        if (is_spinner_fragment($0)) next
        if (is_streaming_fragment($0)) next

        # Handle spinner status lines - only emit when normalized content changes
        if (is_spinner_status_line($0)) {
            if (norm != last_spinner_norm) {
                print
                last_spinner_norm = norm
            }
            next
        }

        # Skip repeated Processing lines
        if (is_processing_line($0)) {
            if (seen_processing) next
            seen_processing = 1
            print
            next
        }

        # Skip consecutive duplicate normalized lines
        if (norm == prev_norm && norm != "") next

        # Skip consecutive horizontal rules
        if (is_hrule($0)) {
            if (was_hrule) next
            was_hrule = 1
        } else {
            was_hrule = 0
        }

        # Skip repeated mode indicators (only show first of each type)
        if (is_mode_indicator($0)) {
            if (seen_mode[$0]) next
            seen_mode[$0] = 1
        }

        # Skip repeated prompt placeholders
        if (is_prompt_placeholder($0)) {
            if (seen_prompt) next
            seen_prompt = 1
        }

        # Skip repeated logo lines
        if (is_logo_line($0)) {
            if (seen_logo[$0]) next
            seen_logo[$0] = 1
        }

        print
        prev_norm = norm
    }
    '
}

# Generate operation logs section
# Usage: generate_operation_logs <op_dir> [verbose]
generate_operation_logs() {
    local op_dir="$1"
    local verbose="${2:-false}"
    local logs_dir="${op_dir}/logs"

    echo "## Operation Logs"
    echo ""

    if [[ ! -d "${logs_dir}" ]]; then
        echo "*No logs directory found*"
        return
    fi

    # Feature log
    if [[ -f "${logs_dir}/feature.log" ]]; then
        echo "### Feature Log"
        echo ""
        include_log_file "${logs_dir}/feature.log" 500 "feature log"
        echo ""
    fi

    # Events log
    if [[ -f "${logs_dir}/events.log" ]]; then
        echo "### Events Log"
        echo ""
        include_log_file "${logs_dir}/events.log" 200 "events log"
        echo ""
    fi

    # Claude log
    if [[ -f "${logs_dir}/claude.log" ]]; then
        echo "### Claude Log"
        echo ""
        include_log_file "${logs_dir}/claude.log" 300 "claude log"
        echo ""
    fi

    # Verbose: include all other logs
    if [[ "${verbose}" = "true" ]]; then
        for log in "${logs_dir}"/*.log; do
            [[ -f "${log}" ]] || continue
            local basename
            basename=$(basename "${log}")
            # Skip already included
            [[ "${basename}" = "feature.log" ]] && continue
            [[ "${basename}" = "events.log" ]] && continue
            [[ "${basename}" = "claude.log" ]] && continue

            echo "### ${basename}"
            echo ""
            include_log_file "${log}" 200 "${basename}"
            echo ""
        done
    fi
}

# Generate git state section
# Usage: generate_git_state <repo_dir> [worktree_dir]
generate_git_state() {
    local repo_dir="$1"
    local worktree_dir="${2:-}"

    echo "## Git State"
    echo ""
    echo "### Main Repository"
    echo ""

    if [[ -d "${repo_dir}/.git" ]] || [[ -f "${repo_dir}/.git" ]]; then
        echo '```'
        echo "# git status"
        git -C "${repo_dir}" status --short 2>/dev/null || echo "(git status failed)"
        echo ""
        echo "# git log --oneline -5"
        git -C "${repo_dir}" log --oneline -5 2>/dev/null || echo "(git log failed)"
        echo ""
        echo "# git branch"
        git -C "${repo_dir}" branch 2>/dev/null || echo "(git branch failed)"
        echo '```'
    else
        echo "*Not a git repository*"
    fi

    # Worktree state if provided
    if [[ -n "${worktree_dir}" ]] && [[ -d "${worktree_dir}" ]]; then
        echo ""
        echo "### Worktree"
        echo ""
        if [[ -d "${worktree_dir}/.git" ]] || [[ -f "${worktree_dir}/.git" ]]; then
            echo '```'
            echo "# Path: ${worktree_dir}"
            echo ""
            echo "# git status"
            git -C "${worktree_dir}" status --short 2>/dev/null || echo "(git status failed)"
            echo ""
            echo "# git log --oneline -5"
            git -C "${worktree_dir}" log --oneline -5 2>/dev/null || echo "(git log failed)"
            echo ""
            echo "# git branch"
            git -C "${worktree_dir}" branch 2>/dev/null || echo "(git branch failed)"
            echo '```'
        else
            echo "*Worktree not initialized*"
        fi
    fi
}

# ============================================================================
# Type Detection Functions
# ============================================================================

# Detect operation type from name or state
# Usage: detect_operation_type <name>
# Returns: feature, plan, worker, daemon, phase, or unknown
detect_operation_type() {
    local name="$1"
    local state_file="${BUILD_DIR}/operations/${name}/state.json"

    # Check if it's a named operation with state
    if [[ -f "${state_file}" ]]; then
        jq -r '.type // "unknown"' "${state_file}"
        return
    fi

    # Check for worker/daemon types
    case "${name}" in
        fix|chore)
            echo "worker"
            ;;
        mergeq|merge|nudge)
            echo "daemon"
            ;;
        plan|decompose)
            echo "phase"
            ;;
        *)
            echo "unknown"
            ;;
    esac
}

# Find most recent operation by type
# Usage: find_most_recent_by_type <type>
find_most_recent_by_type() {
    local type="$1"
    local ops_dir="${BUILD_DIR}/operations"

    [[ ! -d "${ops_dir}" ]] && return 1

    local latest=""
    local latest_time=""

    for state_file in "${ops_dir}"/*/state.json; do
        [[ -f "${state_file}" ]] || continue

        local op_type
        op_type=$(jq -r '.type // "unknown"' "${state_file}")
        [[ "${op_type}" != "${type}" ]] && continue

        local created
        created=$(jq -r '.created_at // ""' "${state_file}")
        local op_name
        op_name=$(jq -r '.name' "${state_file}")

        if [[ -z "${latest_time}" ]] || [[ "${created}" > "${latest_time}" ]]; then
            latest_time="${created}"
            latest="${op_name}"
        fi
    done

    [[ -n "${latest}" ]] && echo "${latest}"
}

# Find most recent operation in a specific phase (or blocked_phase)
# Usage: find_most_recent_by_phase <phase>
find_most_recent_by_phase() {
    local phase="$1"
    local ops_dir="${BUILD_DIR}/operations"

    [[ ! -d "${ops_dir}" ]] && return 1

    local latest=""
    local latest_time=""

    for state_file in "${ops_dir}"/*/state.json; do
        [[ -f "${state_file}" ]] || continue

        local op_phase blocked_phase
        op_phase=$(jq -r '.phase // ""' "${state_file}")
        blocked_phase=$(jq -r '.blocked_phase // ""' "${state_file}")

        [[ "${op_phase}" != "${phase}" && "${blocked_phase}" != "${phase}" ]] && continue

        local created
        created=$(jq -r '.created_at // ""' "${state_file}")
        local op_name
        op_name=$(jq -r '.name' "${state_file}")

        if [[ -z "${latest_time}" ]] || [[ "${created}" > "${latest_time}" ]]; then
            latest_time="${created}"
            latest="${op_name}"
        fi
    done

    [[ -n "${latest}" ]] && echo "${latest}"
}

# Find worktree path for an operation
# Usage: find_worktree_path <op_name>
find_worktree_path() {
    local op_name="$1"

    # Check state for worktree path
    local state_file="${BUILD_DIR}/operations/${op_name}/state.json"
    if [[ -f "${state_file}" ]]; then
        local worktree
        worktree=$(jq -r '.worktree // empty' "${state_file}")
        if [[ -n "${worktree}" ]] && [[ -d "${worktree}" ]]; then
            echo "${worktree}"
            return
        fi
    fi

    # Check standard worktree location
    local worktree_path="${V0_STATE_DIR}/tree/${op_name}"
    if [[ -d "${worktree_path}" ]]; then
        echo "${worktree_path}"
        return
    fi

    # Check feature worktree location
    worktree_path="${V0_STATE_DIR}/tree/feature/${op_name}"
    if [[ -d "${worktree_path}" ]]; then
        echo "${worktree_path}"
        return
    fi
}

# ============================================================================
# Context Collection Functions
# ============================================================================

# Check if operation should include merge context
# Usage: should_include_merge_context <op_name>
should_include_merge_context() {
    local op_name="$1"
    local state_file="${BUILD_DIR}/operations/${op_name}/state.json"

    [[ ! -f "${state_file}" ]] && return 1

    local merge_queued
    merge_queued=$(jq -r '.merge_queued // false' "${state_file}")
    [[ "${merge_queued}" = "true" ]]
}

# Check if operation has dependencies
# Usage: has_dependencies <op_name>
has_dependencies() {
    local op_name="$1"
    local state_file="${BUILD_DIR}/operations/${op_name}/state.json"

    [[ ! -f "${state_file}" ]] && return 1

    local after
    after=$(jq -r '.after // empty' "${state_file}")
    [[ -n "${after}" ]]
}

# Get dependency name
# Usage: get_dependency <op_name>
get_dependency() {
    local op_name="$1"
    local state_file="${BUILD_DIR}/operations/${op_name}/state.json"

    [[ ! -f "${state_file}" ]] && return

    jq -r '.after // empty' "${state_file}"
}

# ============================================================================
# Status Output Functions
# ============================================================================

# Generate v0 status output section
# This should be included in all debug reports for a quick overview
# Usage: generate_v0_status_output
generate_v0_status_output() {
    echo "## v0 Status"
    echo ""
    echo '```'
    if command -v v0 &>/dev/null; then
        v0 status 2>&1 || echo "(v0 status failed)"
    else
        # Try calling v0 from V0_INSTALL_DIR if not in PATH
        if [[ -n "${V0_INSTALL_DIR:-}" ]] && [[ -x "${V0_INSTALL_DIR}/bin/v0" ]]; then
            "${V0_INSTALL_DIR}/bin/v0" status 2>&1 || echo "(v0 status failed)"
        else
            echo "(v0 command not available)"
        fi
    fi
    echo '```'
}
